# SHERLOCK:AI-generated Code Detector

## Implementation of *SHERLOCK*'s experiments in our paper

***SHERLOCK*** is a code-detector designed to distinguish whether a code is generated by human or AI. This repository includes the implementation and run instruction of SHERLOCK.

### The repository is structured as follows:

- Folder `detect-gpt` is our own implementation that perturb given codes to obtain the probability curvature vector. The program functions are all contained in `run_my.py`.

	Because this method includes using pre-trained LLMs, we deployed it on a remote server with GPU. To run on the server, on can execute `bsub < run.sh` and the job will automatically begin, outputs and error logs are stored in `JOBNAME_stdout.log/JOBNAME_stderr.log`.

	Note that when executing on the server, we pre-downloaded the pre-trained LLMs to local cache `model-cache` because it requires access to oversea repository. They're too large so we can't upload them here in this GitHub demo. But we provide our run-logs `147639_stdout.log` and `147640_stdout.log`, as well as the screenshot of our linux server to prove that we really did run the program.

	![linux_screenshot](/Users/tang/ML_final/linux_screenshot.png)

- Folder `code_samples` is a demo of how we obtained our dataset. We cleaned a codeforces competition data, removed the non-ascii decodings (a lot of Japanese), cleaned and splitted the human submission code to use as authentic human-label data. For the AI-generated code, we use the problem set from the same competition to prompt 70b-LLAMA and extracted its solution output.

	`llama_write_code` uses cleaned problems in `problem_descriptions` to prompt LLAMA to write solutions, outputs are stored in `code_solutions*.json`. And then `cleaning_llama_output.py` extracts and saves the AI-generated code in `llama_code_24.json` that we use later in training SHERLOCK.

	Human solutions are in `train.json`.

- Folder `ML_classifier` is where we tested machine learning methods benchmarked against the original threshold methods as proposed in Manning's 2023 detect-GPT paper. See `.ipynb` project files for code details.
